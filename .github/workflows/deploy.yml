# Deploy Workflow
#
# Provisions CloudStack infrastructure and deploys with Kamal.
#
# Required GitHub Secrets:
#   CLOUDSTACK_API_KEY    - CloudStack API key
#   CLOUDSTACK_SECRET_KEY - CloudStack secret key
#   SSH_PRIVATE_KEY       - SSH private key for VM access
#   POSTGRES_USER         - PostgreSQL username (if db_enabled)
#   POSTGRES_PASSWORD     - PostgreSQL password (if db_enabled)
#
# Optional custom container env vars (dotenv format):
#   SECRET_ENV_VARS (secret)   - key=value pairs passed as secret env vars to the container
#   ENV_VARS (variable)    - key=value pairs passed as clear env vars to the container
#
# Note: GITHUB_TOKEN is used for ghcr.io registry access (no separate REGISTRY_TOKEN needed).

name: Deploy

permissions:
  contents: read
  packages: write

concurrency:
  group: deploy-${{ github.repository }}-${{ inputs.env_name || 'preview' }}
  cancel-in-progress: false

on:
  workflow_dispatch:
    inputs:
      env_name:
        description: "Environment name (e.g. preview, staging, production)"
        required: false
        default: "preview"
      zone:
        description: "CloudStack zone"
        type: choice
        default: "ZP01"
        options:
          - ZP01
          - ZP02
      domain:
        description: "Custom domain (optional, enables SSL via Let's Encrypt)"
        required: false
        default: ""
      web_plan:
        description: "Web VM plan"
        type: choice
        default: "small"
        options:
          - micro
          - small
          - medium
          - large
          - xlarge
          - 2xlarge
          - 4xlarge
      blob_disk_size_gb:
        description: "Web blob disk size in GB"
        type: number
        default: 20
      workers_enabled:
        description: "Enable worker VMs"
        type: boolean
        default: false
      workers_replicas:
        description: "Number of worker replicas"
        type: number
        default: 1
      workers_cmd:
        description: "Command for worker containers"
        required: false
        default: "sleep infinity"
      workers_plan:
        description: "Worker VM plan"
        type: choice
        default: "small"
        options:
          - micro
          - small
          - medium
          - large
          - xlarge
          - 2xlarge
          - 4xlarge
      db_enabled:
        description: "Enable database VM"
        type: boolean
        default: false
      db_plan:
        description: "Database VM plan"
        type: choice
        default: "medium"
        options:
          - micro
          - small
          - medium
          - large
          - xlarge
          - 2xlarge
          - 4xlarge
      db_disk_size_gb:
        description: "Database disk size in GB"
        type: number
        default: 20
      automatic_reboot:
        description: "Enable automatic reboot after unattended upgrades"
        type: boolean
        default: true
      recover:
        description: "Recover from snapshots (cross-zone disaster recovery)"
        type: boolean
        default: false
      automatic_reboot_time_utc:
        description: "Automatic reboot time in HH:MM UTC"
        required: false
        default: "05:00"

  workflow_call:
    inputs:
      env_name:
        type: string
        default: "preview"
      zone:
        type: string
        default: "ZP01"
      domain:
        type: string
        default: ""
      web_plan:
        type: string
        default: "small"
      blob_disk_size_gb:
        type: number
        default: 20
      workers_enabled:
        type: boolean
        default: false
      workers_replicas:
        type: number
        default: 1
      workers_cmd:
        type: string
        default: "sleep infinity"
      workers_plan:
        type: string
        default: "small"
      db_enabled:
        type: boolean
        default: false
      db_plan:
        type: string
        default: "medium"
      db_disk_size_gb:
        type: number
        default: 20
      automatic_reboot:
        type: boolean
        default: true
      recover:
        type: boolean
        default: false
      automatic_reboot_time_utc:
        type: string
        default: "05:00"
      env_vars:
        type: string
        default: ""
        description: "Dotenv-formatted key=value pairs for clear container env vars"
    secrets:
      CLOUDSTACK_API_KEY:
        required: true
      CLOUDSTACK_SECRET_KEY:
        required: true
      SSH_PRIVATE_KEY:
        required: true
      POSTGRES_USER:
        required: false
      POSTGRES_PASSWORD:
        required: false
      SECRET_ENV_VARS:
        required: false
    outputs:
      web_ip:
        description: "Web VM public IP"
        value: ${{ jobs.deploy.outputs.web_ip }}
      worker_ips:
        description: "Worker VM public IPs (JSON array)"
        value: ${{ jobs.deploy.outputs.worker_ips }}
      db_ip:
        description: "Database VM public IP"
        value: ${{ jobs.deploy.outputs.db_ip }}
      db_internal_ip:
        description: "Database VM internal IP"
        value: ${{ jobs.deploy.outputs.db_internal_ip }}

jobs:
  deploy:
    runs-on: ubuntu-latest
    outputs:
      web_ip: ${{ steps.outputs.outputs.web_ip }}
      worker_ips: ${{ steps.outputs.outputs.worker_ips }}
      db_ip: ${{ steps.outputs.outputs.db_ip }}
      db_internal_ip: ${{ steps.outputs.outputs.db_internal_ip }}

    steps:
      - name: Validate secrets
        if: inputs.db_enabled
        env:
          POSTGRES_USER: ${{ secrets.POSTGRES_USER }}
          POSTGRES_PASSWORD: ${{ secrets.POSTGRES_PASSWORD }}
        run: |
          missing=()
          [ -z "$POSTGRES_USER" ] && missing+=("POSTGRES_USER")
          [ -z "$POSTGRES_PASSWORD" ] && missing+=("POSTGRES_PASSWORD")
          if [ ${#missing[@]} -gt 0 ]; then
            echo "::error::db_enabled is true but required secrets are missing: ${missing[*]}"
            exit 1
          fi

      - name: Checkout application repository
        uses: actions/checkout@v4

      - name: Checkout infrastructure scripts
        uses: actions/checkout@v4
        with:
          repository: gmautner/locaweb-cloud-deploy
          path: _infra

      - name: Build configuration
        env:
          INPUT_ZONE: ${{ inputs.zone }}
          INPUT_DOMAIN: ${{ inputs.domain }}
          INPUT_WEB_PLAN: ${{ inputs.web_plan }}
          INPUT_BLOB_DISK_SIZE_GB: ${{ inputs.blob_disk_size_gb }}
          INPUT_WORKERS_ENABLED: ${{ inputs.workers_enabled }}
          INPUT_WORKERS_REPLICAS: ${{ inputs.workers_replicas }}
          INPUT_WORKERS_PLAN: ${{ inputs.workers_plan }}
          INPUT_DB_ENABLED: ${{ inputs.db_enabled }}
          INPUT_DB_PLAN: ${{ inputs.db_plan }}
          INPUT_DB_DISK_SIZE_GB: ${{ inputs.db_disk_size_gb }}
          INPUT_RECOVER: ${{ inputs.recover }}
        run: python3 _infra/scripts/build_config.py

      - name: Extract SSH public key
        env:
          SSH_PRIVATE_KEY: ${{ secrets.SSH_PRIVATE_KEY }}
        run: |
          install -m 600 /dev/null /tmp/ssh_key
          printf '%s\n' "$SSH_PRIVATE_KEY" > /tmp/ssh_key
          ssh-keygen -y -f /tmp/ssh_key > /tmp/ssh_key.pub
          echo "Public key extracted successfully."

      - name: Install and configure CloudMonkey
        env:
          CLOUDSTACK_API_KEY: ${{ secrets.CLOUDSTACK_API_KEY }}
          CLOUDSTACK_SECRET_KEY: ${{ secrets.CLOUDSTACK_SECRET_KEY }}
        run: |
          wget -q https://github.com/apache/cloudstack-cloudmonkey/releases/latest/download/cmk.linux.x86-64
          chmod +x cmk.linux.x86-64
          sudo mv cmk.linux.x86-64 /usr/local/bin/cmk
          cmk set url "https://painel-cloud.locaweb.com.br/client/api"
          cmk set apikey "$CLOUDSTACK_API_KEY"
          cmk set secretkey "$CLOUDSTACK_SECRET_KEY"
          cmk set output json
          cmk sync
          echo "Verifying CloudStack connectivity..."
          cmk list zones filter=name
          echo "CloudMonkey configured successfully."

      - name: Provision infrastructure
        run: |
          recover_flag=""
          if [ "${{ inputs.recover }}" = "true" ]; then
            recover_flag="--recover"
          fi
          python3 -u _infra/scripts/provision_infrastructure.py \
            --repo-name "${{ github.event.repository.name }}" \
            --unique-id "${{ github.repository_id }}" \
            --env-name "${{ inputs.env_name || 'preview' }}" \
            --config /tmp/config.json \
            --public-key /tmp/ssh_key.pub \
            --output /tmp/provision-output.json \
            $recover_flag

      - name: Set outputs
        id: outputs
        run: |
          python3 << 'PYEOF'
          import json, os
          d = json.load(open('/tmp/provision-output.json'))
          with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
              f.write(f"web_ip={d.get('web_ip', '')}\n")
              f.write(f"worker_ips={json.dumps(d.get('worker_ips', []))}\n")
              f.write(f"db_ip={d.get('db_ip', '')}\n")
              f.write(f"db_internal_ip={d.get('db_internal_ip', '')}\n")
          PYEOF

      - name: Upload provisioning output
        uses: actions/upload-artifact@v4
        with:
          name: provision-output
          path: /tmp/provision-output.json
          retention-days: 90

      - name: Print summary
        run: |
          python3 << 'PYEOF' >> $GITHUB_STEP_SUMMARY
          import json
          d = json.load(open('/tmp/provision-output.json'))
          print('## Infrastructure Provisioning Complete')
          print('')
          print('| Resource | Public IP |')
          print('|----------|-----------|')
          print(f'| Web | {d.get("web_ip", "N/A")} |')
          for i, ip in enumerate(d.get("worker_ips", []), 1):
              print(f'| Worker {i} | {ip} |')
          if d.get("db_ip"):
              print(f'| Database | {d["db_ip"]} |')
          PYEOF

      - name: Configure unattended upgrades
        run: |
          python3 -u _infra/scripts/configure_unattended_upgrades.py \
            --ssh-key /tmp/ssh_key \
            --provision-output /tmp/provision-output.json \
            --automatic-reboot "${{ inputs.automatic_reboot }}" \
            --reboot-time "${{ inputs.automatic_reboot_time_utc }}"

      - name: Install Kamal
        run: |
          sudo gem install kamal --no-document
          kamal version

      - name: Prepare SSH key for Kamal
        run: |
          mkdir -p .kamal
          cp /tmp/ssh_key .kamal/ssh_key
          chmod 600 .kamal/ssh_key

      - name: Create Kamal secrets and env vars
        env:
          SECRET_ENV_VARS: ${{ secrets.SECRET_ENV_VARS }}
          ENV_VARS: ${{ inputs.env_vars || vars.ENV_VARS }}
          INPUT_DB_ENABLED: ${{ inputs.db_enabled }}
        run: |
          pip install -q python-dotenv
          python3 _infra/scripts/create_kamal_secrets.py

      - name: Resolve Postgres image tag
        if: inputs.db_enabled
        id: pg_image
        run: |
          pip install -q requests
          echo "image=$(python3 _infra/scripts/resolve_postgres_tag.py)" >> "$GITHUB_OUTPUT"

      - name: Generate Kamal deploy config
        env:
          INPUT_WORKERS_ENABLED: ${{ inputs.workers_enabled }}
          INPUT_WORKERS_CMD: ${{ inputs.workers_cmd }}
          INPUT_DB_ENABLED: ${{ inputs.db_enabled }}
          INPUT_DB_PLAN: ${{ inputs.db_plan }}
          INPUT_DOMAIN: ${{ inputs.domain }}
          POSTGRES_IMAGE: ${{ steps.pg_image.outputs.image }}
          REPO_NAME: ${{ github.event.repository.name }}
          REPO_FULL: ${{ github.repository }}
          REPO_OWNER: ${{ github.repository_owner }}
        run: python3 _infra/scripts/generate_kamal_config.py

      - name: Deploy with Kamal
        env:
          KAMAL_REGISTRY_PASSWORD: ${{ secrets.GITHUB_TOKEN }}
          POSTGRES_USER: ${{ secrets.POSTGRES_USER }}
          POSTGRES_PASSWORD: ${{ secrets.POSTGRES_PASSWORD }}
          POSTGRES_HOST: ${{ steps.outputs.outputs.db_internal_ip }}
          POSTGRES_DB: ${{ github.event.repository.name }}
        run: |
          export DATABASE_URL="postgres://$POSTGRES_USER:$POSTGRES_PASSWORD@$POSTGRES_HOST:5432/$POSTGRES_DB"
          source /tmp/kamal_custom_secrets.env
          kamal setup

      - name: Reboot DB accessory if tuning changed
        if: inputs.db_enabled
        env:
          KAMAL_REGISTRY_PASSWORD: ${{ secrets.GITHUB_TOKEN }}
          POSTGRES_USER: ${{ secrets.POSTGRES_USER }}
          POSTGRES_PASSWORD: ${{ secrets.POSTGRES_PASSWORD }}
          POSTGRES_HOST: ${{ steps.outputs.outputs.db_internal_ip }}
          POSTGRES_DB: ${{ github.event.repository.name }}
          DB_IP: ${{ steps.outputs.outputs.db_ip }}
          REPO_NAME: ${{ github.event.repository.name }}
        run: |
          export DATABASE_URL="postgres://$POSTGRES_USER:$POSTGRES_PASSWORD@$POSTGRES_HOST:5432/$POSTGRES_DB"
          source /tmp/kamal_custom_secrets.env
          desired_cmd=$(python3 -c "import yaml; c=yaml.safe_load(open('config/deploy.yml')); print(c.get('accessories',{}).get('db',{}).get('cmd',''))")
          current_cmd=$(ssh -i .kamal/ssh_key -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null \
            root@"$DB_IP" "docker inspect --format '{{join .Config.Cmd \" \"}}' ${REPO_NAME}-db" 2>/dev/null || echo "")
          if [ "$desired_cmd" != "$current_cmd" ]; then
            echo "PostgreSQL tuning parameters changed, rebooting DB accessory..."
            echo "  Current: $current_cmd"
            echo "  Desired: $desired_cmd"
            kamal accessory reboot db
          else
            echo "PostgreSQL tuning parameters unchanged, skipping reboot."
          fi

      - name: Print Kamal deployment summary
        env:
          INPUT_DOMAIN: ${{ inputs.domain }}
        run: |
          python3 << 'PYEOF' >> $GITHUB_STEP_SUMMARY
          import json, os
          d = json.load(open('/tmp/provision-output.json'))
          web_ip = d.get('web_ip', 'N/A')
          domain = os.environ.get('INPUT_DOMAIN', '').strip()
          sha = os.environ.get('GITHUB_SHA', 'unknown')[:7]
          repo = os.environ.get('GITHUB_REPOSITORY', '')
          if domain:
              url = f'https://{domain}'
              health = f'https://{domain}/up'
          else:
              url = f'http://{web_ip}'
              health = f'http://{web_ip}/up'
          print('')
          print('## Kamal Deployment Complete')
          print('')
          print(f'- **Commit:** `{sha}`')
          print(f'- **Image:** `ghcr.io/{repo}:{sha}`')
          print(f'- **URL:** {url}')
          print(f'- **Health check:** {health}')
          if domain:
              print(f'- **Domain:** `{domain}` (SSL via Let\'s Encrypt)')
              print(f'- **Public IP:** `{web_ip}` (point DNS A record here)')
          PYEOF
